{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fish classification using ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import default libraries\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from IPython.core.debugger import Tracer # call Tracer()() for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import PyTorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# intermediate folder\n",
    "intermediate_path = os.path.join(\"..\", \"intermediate\")\n",
    "# train/val folders\n",
    "train_path = os.path.join(intermediate_path, \"train\")\n",
    "val_path = os.path.join(intermediate_path, \"val\")\n",
    "valnum = 500 # number of images for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create intermediate folder, copy train data, and split\n",
    "if not os.path.isdir(train_path):\n",
    "    shutil.copytree(\"../data/train/\", train_path)\n",
    "    # remove hidden folders\n",
    "    for hidden_folder in glob.glob(train_path + \"/.*\"):\n",
    "        !rm -r $hidden_folder\n",
    "\n",
    "if not os.path.isdir(val_path):\n",
    "    import numpy as np\n",
    "    np.random.seed(7)\n",
    "    g = glob.glob(train_path + \"/*/*.jpg\")\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(valnum):\n",
    "        os.renames(shuf[i], shuf[i].replace(\"train\", \"val\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global parameters and utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# global parameters\n",
    "arch = \"resnet50\"\n",
    "num_workers = 4\n",
    "batch_size = 16 # out of memory for 32 or 64\n",
    "learning_rate = 1e-4\n",
    "print_freq = 10\n",
    "pretrained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "# TODO: try to use torchnet utilities\n",
    "# link: https://github.com/pytorch/tnt/\n",
    "# replace: AverageMeter, accurary\n",
    "def save_checkpoint(state, is_best, filename=\"checkpoint.pth.tar\"):\n",
    "    checkpoint_filepath = os.path.join(intermediate_path, filename)\n",
    "    torch.save(state, checkpoint_filepath)\n",
    "    if is_best:\n",
    "        model_best_filepath = os.path.join(intermediate_path,\n",
    "                                           \"model_best.pth.tar\")\n",
    "        shutil.copyfile(checkpoint_filepath, model_best_filepath)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = learning_rate * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/validate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train function\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        # here we should call cuda() for input;\n",
    "        # in the ImageNet example, the model is parallel by\n",
    "        # torch.nn.DataParallel(model).cuda(), so no need to call cuda() there;\n",
    "        # the option async=True works with pin_memory of DataLoader\n",
    "        # pin_memory slows down DataLoader but fastens data transfer from\n",
    "        # CPU to GPU\n",
    "        input = input.cuda(async=True)\n",
    "        target = target.cuda(async=True)\n",
    "        input_var = torch.autograd.Variable(input)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,))[0] #notice [0] here\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "             print(\"Epoch: [{0}][{1}/{2}]\\t\"\n",
    "                   \"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n",
    "                   \"Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\"\n",
    "                   \"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n",
    "                   \"Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\".format(\n",
    "                       epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                       data_time=data_time, loss=losses, top1=top1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# validate function\n",
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        input = input.cuda(async=True)\n",
    "        target = target.cuda(async=True)\n",
    "        # volatile=True means that no need to compute gradients\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target, topk=(1,))[0]\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "             print(\"Test: [{0}/{1}]\\t\"\n",
    "                   \"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n",
    "                   \"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n",
    "                   \"Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\".format(\n",
    "                       i, len(val_loader), batch_time=batch_time,\n",
    "                       loss=losses, top1=top1))\n",
    "\n",
    "    print(\" * Prec@1 {top1.avg:.3f}\"\n",
    "          .format(top1=top1))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet (\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu): ReLU (inplace)\n",
       "  (maxpool): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
       "  (layer1): Sequential (\n",
       "    (0): Bottleneck (\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck (\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (2): Bottleneck (\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential (\n",
       "    (0): Bottleneck (\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck (\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (2): Bottleneck (\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (3): Bottleneck (\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential (\n",
       "    (0): Bottleneck (\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (2): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (3): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (4): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (5): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential (\n",
       "    (0): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck (\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (2): Bottleneck (\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d (\n",
       "  )\n",
       "  (fc): Linear (2048 -> 8)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = models.resnet50(pretrained=pretrained)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "# replace the last fully-connected layer\n",
    "bn_expansion = 4\n",
    "model.fc = nn.Linear(512 * bn_expansion, 8)\n",
    "# for 1 GPU, it is unnecessary to use DataParallel\n",
    "#model = torch.nn.DataParallel(model).cuda()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set this flag to get 2x speed improvement\n",
    "# according to PyTorch Slack #beginner channel\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(train_path, transforms.Compose([\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(val_path, transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/205]\tTime 1.770 (1.770)\tData 0.616 (0.616)\tLoss 2.2480 (2.2480)\tPrec@1 0.000 (0.000)\t\n",
      "Epoch: [0][10/205]\tTime 0.073 (0.227)\tData 0.000 (0.056)\tLoss 1.7457 (1.9839)\tPrec@1 43.750 (25.568)\t\n",
      "Epoch: [0][20/205]\tTime 0.078 (0.175)\tData 0.006 (0.051)\tLoss 1.9110 (1.8483)\tPrec@1 37.500 (32.738)\t\n",
      "Epoch: [0][30/205]\tTime 0.077 (0.159)\tData 0.005 (0.052)\tLoss 1.3527 (1.7629)\tPrec@1 68.750 (37.702)\t\n",
      "Epoch: [0][40/205]\tTime 0.196 (0.150)\tData 0.123 (0.052)\tLoss 1.8813 (1.6992)\tPrec@1 43.750 (41.006)\t\n",
      "Epoch: [0][50/205]\tTime 0.072 (0.142)\tData 0.000 (0.049)\tLoss 1.5655 (1.6581)\tPrec@1 37.500 (42.892)\t\n",
      "Epoch: [0][60/205]\tTime 0.196 (0.140)\tData 0.123 (0.050)\tLoss 1.8922 (1.6666)\tPrec@1 43.750 (42.520)\t\n",
      "Epoch: [0][70/205]\tTime 0.076 (0.135)\tData 0.004 (0.048)\tLoss 1.6285 (1.6835)\tPrec@1 50.000 (42.077)\t\n",
      "Epoch: [0][80/205]\tTime 0.113 (0.134)\tData 0.041 (0.048)\tLoss 1.8330 (1.6778)\tPrec@1 37.500 (41.975)\t\n",
      "Epoch: [0][90/205]\tTime 0.077 (0.132)\tData 0.005 (0.048)\tLoss 1.5061 (1.6651)\tPrec@1 50.000 (42.445)\t\n",
      "Epoch: [0][100/205]\tTime 0.134 (0.131)\tData 0.061 (0.048)\tLoss 1.7884 (1.6573)\tPrec@1 37.500 (42.946)\t\n",
      "Epoch: [0][110/205]\tTime 0.076 (0.130)\tData 0.004 (0.048)\tLoss 1.5068 (1.6486)\tPrec@1 56.250 (43.187)\t\n",
      "Epoch: [0][120/205]\tTime 0.103 (0.129)\tData 0.031 (0.048)\tLoss 1.4867 (1.6431)\tPrec@1 56.250 (43.285)\t\n",
      "Epoch: [0][130/205]\tTime 0.097 (0.128)\tData 0.024 (0.047)\tLoss 1.3221 (1.6384)\tPrec@1 50.000 (43.321)\t\n",
      "Epoch: [0][140/205]\tTime 0.076 (0.128)\tData 0.004 (0.048)\tLoss 1.6814 (1.6326)\tPrec@1 31.250 (43.440)\t\n",
      "Epoch: [0][150/205]\tTime 0.110 (0.127)\tData 0.038 (0.047)\tLoss 1.4724 (1.6327)\tPrec@1 43.750 (43.626)\t\n",
      "Epoch: [0][160/205]\tTime 0.076 (0.126)\tData 0.004 (0.047)\tLoss 1.5550 (1.6259)\tPrec@1 37.500 (43.866)\t\n",
      "Epoch: [0][170/205]\tTime 0.132 (0.126)\tData 0.060 (0.047)\tLoss 2.0878 (1.6215)\tPrec@1 25.000 (43.933)\t\n",
      "Epoch: [0][180/205]\tTime 0.072 (0.125)\tData 0.000 (0.047)\tLoss 1.4229 (1.6118)\tPrec@1 56.250 (43.992)\t\n",
      "Epoch: [0][190/205]\tTime 0.165 (0.125)\tData 0.093 (0.047)\tLoss 1.5014 (1.5992)\tPrec@1 50.000 (44.437)\t\n",
      "Epoch: [0][200/205]\tTime 0.078 (0.124)\tData 0.006 (0.047)\tLoss 1.1783 (1.5953)\tPrec@1 50.000 (44.403)\t\n",
      "Test: [0/32]\tTime 0.800 (0.800)\tLoss 3.2911 (3.2911)\tPrec@1 0.000 (0.000)\t\n",
      "Test: [10/32]\tTime 0.063 (0.191)\tLoss 0.6593 (1.3768)\tPrec@1 100.000 (72.727)\t\n",
      "Test: [20/32]\tTime 0.392 (0.174)\tLoss 2.4729 (1.3354)\tPrec@1 0.000 (68.452)\t\n",
      "Test: [30/32]\tTime 0.063 (0.160)\tLoss 1.6122 (1.4301)\tPrec@1 0.000 (46.573)\t\n",
      " * Prec@1 46.200\n",
      "Epoch: [1][0/205]\tTime 0.703 (0.703)\tData 0.630 (0.630)\tLoss 1.4464 (1.4464)\tPrec@1 43.750 (43.750)\t\n",
      "Epoch: [1][10/205]\tTime 0.072 (0.169)\tData 0.000 (0.097)\tLoss 1.7240 (1.4422)\tPrec@1 31.250 (47.159)\t\n",
      "Epoch: [1][20/205]\tTime 0.227 (0.148)\tData 0.155 (0.076)\tLoss 1.0989 (1.4494)\tPrec@1 62.500 (48.512)\t\n",
      "Epoch: [1][30/205]\tTime 0.072 (0.135)\tData 0.000 (0.063)\tLoss 1.5136 (1.4460)\tPrec@1 37.500 (48.387)\t\n",
      "Epoch: [1][40/205]\tTime 0.255 (0.133)\tData 0.181 (0.061)\tLoss 1.3045 (1.4639)\tPrec@1 62.500 (47.104)\t\n",
      "Epoch: [1][50/205]\tTime 0.072 (0.128)\tData 0.000 (0.056)\tLoss 1.4546 (1.4741)\tPrec@1 62.500 (46.691)\t\n",
      "Epoch: [1][60/205]\tTime 0.237 (0.127)\tData 0.164 (0.055)\tLoss 1.8273 (1.4858)\tPrec@1 31.250 (46.516)\t\n",
      "Epoch: [1][70/205]\tTime 0.072 (0.125)\tData 0.000 (0.053)\tLoss 1.6388 (1.4697)\tPrec@1 37.500 (47.095)\t\n",
      "Epoch: [1][80/205]\tTime 0.240 (0.125)\tData 0.166 (0.053)\tLoss 1.2667 (1.4712)\tPrec@1 56.250 (47.222)\t\n",
      "Epoch: [1][90/205]\tTime 0.072 (0.124)\tData 0.000 (0.051)\tLoss 1.6422 (1.4828)\tPrec@1 50.000 (46.497)\t\n",
      "Epoch: [1][100/205]\tTime 0.242 (0.124)\tData 0.169 (0.051)\tLoss 1.6708 (1.4819)\tPrec@1 37.500 (46.658)\t\n",
      "Epoch: [1][110/205]\tTime 0.072 (0.123)\tData 0.000 (0.050)\tLoss 1.6965 (1.4739)\tPrec@1 43.750 (47.016)\t\n",
      "Epoch: [1][120/205]\tTime 0.248 (0.123)\tData 0.175 (0.050)\tLoss 1.3723 (1.4661)\tPrec@1 50.000 (47.262)\t\n",
      "Epoch: [1][130/205]\tTime 0.072 (0.122)\tData 0.000 (0.049)\tLoss 1.4326 (1.4618)\tPrec@1 56.250 (47.424)\t\n",
      "Epoch: [1][140/205]\tTime 0.233 (0.122)\tData 0.159 (0.049)\tLoss 1.5866 (1.4625)\tPrec@1 31.250 (47.429)\t\n",
      "Epoch: [1][150/205]\tTime 0.072 (0.122)\tData 0.000 (0.049)\tLoss 1.6613 (1.4680)\tPrec@1 43.750 (47.310)\t\n",
      "Epoch: [1][160/205]\tTime 0.238 (0.122)\tData 0.164 (0.049)\tLoss 1.5007 (1.4616)\tPrec@1 50.000 (47.787)\t\n",
      "Epoch: [1][170/205]\tTime 0.096 (0.121)\tData 0.024 (0.048)\tLoss 1.7713 (1.4680)\tPrec@1 43.750 (47.734)\t\n",
      "Epoch: [1][180/205]\tTime 0.197 (0.121)\tData 0.124 (0.048)\tLoss 1.5220 (1.4650)\tPrec@1 25.000 (47.825)\t\n",
      "Epoch: [1][190/205]\tTime 0.103 (0.120)\tData 0.031 (0.048)\tLoss 1.5399 (1.4596)\tPrec@1 37.500 (48.004)\t\n",
      "Epoch: [1][200/205]\tTime 0.232 (0.121)\tData 0.160 (0.048)\tLoss 1.2307 (1.4574)\tPrec@1 68.750 (48.072)\t\n",
      "Test: [0/32]\tTime 0.807 (0.807)\tLoss 2.6516 (2.6516)\tPrec@1 0.000 (0.000)\t\n",
      "Test: [10/32]\tTime 0.063 (0.191)\tLoss 0.6672 (1.2043)\tPrec@1 100.000 (71.591)\t\n",
      "Test: [20/32]\tTime 0.391 (0.174)\tLoss 1.9474 (1.2100)\tPrec@1 0.000 (66.369)\t\n",
      "Test: [30/32]\tTime 0.063 (0.160)\tLoss 1.4438 (1.2996)\tPrec@1 31.250 (52.823)\t\n",
      " * Prec@1 52.600\n",
      "Epoch: [2][0/205]\tTime 1.326 (1.326)\tData 1.254 (1.254)\tLoss 1.6486 (1.6486)\tPrec@1 43.750 (43.750)\t\n",
      "Epoch: [2][10/205]\tTime 0.072 (0.225)\tData 0.000 (0.153)\tLoss 1.1478 (1.3360)\tPrec@1 62.500 (54.545)\t\n",
      "Epoch: [2][20/205]\tTime 0.269 (0.180)\tData 0.195 (0.107)\tLoss 1.6072 (1.3896)\tPrec@1 43.750 (50.595)\t\n",
      "Epoch: [2][30/205]\tTime 0.072 (0.157)\tData 0.000 (0.084)\tLoss 1.3747 (1.4047)\tPrec@1 50.000 (50.202)\t\n",
      "Epoch: [2][40/205]\tTime 0.269 (0.150)\tData 0.196 (0.077)\tLoss 1.3503 (1.3896)\tPrec@1 56.250 (51.067)\t\n",
      "Epoch: [2][50/205]\tTime 0.074 (0.142)\tData 0.001 (0.069)\tLoss 1.7442 (1.3850)\tPrec@1 31.250 (50.980)\t\n",
      "Epoch: [2][60/205]\tTime 0.268 (0.139)\tData 0.194 (0.067)\tLoss 1.3021 (1.3798)\tPrec@1 56.250 (51.127)\t\n",
      "Epoch: [2][70/205]\tTime 0.072 (0.135)\tData 0.000 (0.062)\tLoss 1.1168 (1.3810)\tPrec@1 68.750 (51.320)\t\n",
      "Epoch: [2][80/205]\tTime 0.284 (0.134)\tData 0.211 (0.061)\tLoss 1.4644 (1.3811)\tPrec@1 43.750 (51.389)\t\n",
      "Epoch: [2][90/205]\tTime 0.072 (0.131)\tData 0.000 (0.059)\tLoss 1.1766 (1.3848)\tPrec@1 56.250 (50.824)\t\n",
      "Epoch: [2][100/205]\tTime 0.250 (0.131)\tData 0.177 (0.058)\tLoss 1.5277 (1.3847)\tPrec@1 43.750 (51.423)\t\n",
      "Epoch: [2][110/205]\tTime 0.082 (0.129)\tData 0.010 (0.056)\tLoss 1.5304 (1.3881)\tPrec@1 43.750 (51.351)\t\n",
      "Epoch: [2][120/205]\tTime 0.243 (0.129)\tData 0.171 (0.056)\tLoss 1.1748 (1.3856)\tPrec@1 56.250 (51.446)\t\n",
      "Epoch: [2][130/205]\tTime 0.073 (0.127)\tData 0.000 (0.055)\tLoss 1.4068 (1.3793)\tPrec@1 62.500 (51.813)\t\n",
      "Epoch: [2][140/205]\tTime 0.236 (0.127)\tData 0.164 (0.055)\tLoss 1.3205 (1.3799)\tPrec@1 56.250 (51.551)\t\n",
      "Epoch: [2][150/205]\tTime 0.073 (0.126)\tData 0.000 (0.054)\tLoss 1.6108 (1.3739)\tPrec@1 31.250 (51.821)\t\n",
      "Epoch: [2][160/205]\tTime 0.243 (0.126)\tData 0.170 (0.053)\tLoss 1.1977 (1.3675)\tPrec@1 56.250 (52.096)\t\n",
      "Epoch: [2][170/205]\tTime 0.079 (0.125)\tData 0.005 (0.052)\tLoss 1.1371 (1.3701)\tPrec@1 62.500 (51.937)\t\n",
      "Epoch: [2][180/205]\tTime 0.202 (0.125)\tData 0.130 (0.052)\tLoss 1.2262 (1.3696)\tPrec@1 43.750 (51.968)\t\n",
      "Epoch: [2][190/205]\tTime 0.073 (0.124)\tData 0.000 (0.052)\tLoss 1.3669 (1.3686)\tPrec@1 50.000 (51.898)\t\n",
      "Epoch: [2][200/205]\tTime 0.232 (0.124)\tData 0.159 (0.052)\tLoss 1.5196 (1.3694)\tPrec@1 50.000 (51.928)\t\n",
      "Test: [0/32]\tTime 0.744 (0.744)\tLoss 2.7470 (2.7470)\tPrec@1 0.000 (0.000)\t\n",
      "Test: [10/32]\tTime 0.063 (0.176)\tLoss 0.6674 (1.2225)\tPrec@1 100.000 (71.023)\t\n",
      "Test: [20/32]\tTime 0.392 (0.166)\tLoss 1.6216 (1.1609)\tPrec@1 12.500 (66.667)\t\n",
      "Test: [30/32]\tTime 0.063 (0.154)\tLoss 1.4298 (1.2322)\tPrec@1 31.250 (55.847)\t\n",
      " * Prec@1 55.800\n"
     ]
    }
   ],
   "source": [
    "best_prec1 = 0\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    prec1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best prec@1 and save checkpoint\n",
    "    is_best = prec1 > best_prec1\n",
    "    best_prec1 = max(prec1, best_prec1)\n",
    "    save_checkpoint({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"arch\": arch,\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"best_prec1\": best_prec1,\n",
    "    }, is_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pydata]",
   "language": "python",
   "name": "conda-env-pydata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
